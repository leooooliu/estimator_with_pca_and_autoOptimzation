# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZQ6hSDgqGiQdWJuNB186u1tmk8kCLq52
"""

# -*- coding: utf-8 -*-
"""data_challenge_tempus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o8PmOUA6QhIbmbR4iCYdl4fyeRDPPzw2
"""

# numpy and pandas for data manipulation
import numpy as np
import pandas as pd 

# sklearn preprocessing import model
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.datasets import make_classification
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support as score
from sklearn.decomposition import PCA
from IPython.display import display
# File system manangement
import os
from collections import Counter
# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# matplotlib and seaborn for plotting
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.base import BaseEstimator
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
random_state = 0


def explore_analysis(df,y_col_name='response'):
  
  print('dataset overview:')
  print('-----------------')
  display(df.head(5))
  print('\n')
  print('dataset summary:')
  print('-----------------')
  print('the dataset has {} rows and {} columns'.format(df.shape[0],df.shape[1]))

  y_sum=Counter(df[y_col_name])
  print('the target data has {} classes'.format(len(y_sum)))
  for key,value in y_sum.items():
    print('class {} has {} instances'.format(key,value))
  assert (not (df.isnull().any().any())),'there is None value in the dataset, please impute before feature engineered and feeding into model'
    


class DummyEstimator(BaseEstimator):
    def fit(self): pass
    def score(self): pass



class clf_4_high_dimensional_data(BaseEstimator):
  def __init__(self,use_pca=False,use_model_selection=True):
    self.use_pca=use_pca
  def fit(self,X,y):
    if self.use_pca:
      pipe = Pipeline([('pca',PCA(n_components=0.95)),('clf', DummyEstimator())]) # Placeholder Estimator 
    else:
      pipe=Pipeline([('clf', DummyEstimator())]) 
    # Candidate learning algorithms and their hyperparameters
    search_space = [{'clf': [LogisticRegression()], # Actual Estimator
                     'clf__penalty': ['l1', 'l2'],
                     'clf__C': np.logspace(0, 4, 10)
                    },

                    {'clf': [RandomForestClassifier()],  # Actual Estimator
                     'clf__max_depth': [5,6,7,8,9]},
    #                    'clf__max_features':list(np.arange(0,d,round(d/10)))

                    {'clf': [GradientBoostingClassifier()],
                    'clf__max_depth':[4,5,6,7,8,9],
    #                 'clf__max_features':list(np.arange(0,d,round(d/10))),
                    'clf__learning_rate':[0.1,0.2,0.3],
                    'clf__n_estimators':[1,2,3,4]}
                   ]
    
    self.estimator_selection=GridSearchCV(pipe,search_space,scoring='f1')
    self.estimator_selection.fit(X,y)
    print('\n')
    print('the best estimator and its paramators is: ')
    print(self.estimator_selection.best_estimator_.steps[0][1])
    print('\n')
    print('model is already trained, please call method of predict or score for predicting and validating')
    print('\n')
    print('the result of PCA:')
    if self.use_pca:
      pca=self.estimiator.best_estimator_.named_steps['pca']
      X_reduced = pca.fit_transform(X)
      fig, ax = plt.subplots(figsize=(8,8))
      d=pca.n_components_
      cumsum = np.cumsum(pca.explained_variance_ratio_)
      plt.bar(range(d), cumsum[:d]*100, label='Cumulative _Sum_of_Explained _Varaince', color = 'g',alpha=0.5)
      plt.title("Around 95% of variance is explained by the Fisrt {} colmns ".format(d)) #bitch, got you, you copied shit from the internet, dont forget to change the param
      plt.ylim(ymax=100)
#     return self
  def predict(self,X,y=None):
    return self.estimator_selection.predict(X)
  def score(self,X,y):
    prediction = self.estimator_selection.predict(X)
    precision, recall, fscore, support = score(y, prediction, average = "weighted")
    print("Precision: {:.2f}".format(precision))
    print("Recall: {:.2f}".format(recall))
    print("F-score: {:.2f}".format(fscore))
    return precision, recall, fscore